{"cells":[{"cell_type":"markdown","metadata":{"id":"hinq2nLQvg_2"},"source":["## Preprocess\n","### Process toxin-antitoxin (TA) genomic sequence to prepare dataset for EVO fine-tuning\n","- Dataset: TADB 3.0 (https://bioinfo-mml.sjtu.edu.cn/TADB3/index.php)\n","- Toxin-Antitoxin type: Type II, Experimentally validated + in silico predicted\n","\n","Evo: Fine-tuning requirements:\n","- MAX_seq_LENGTH = 1024 # Context length for finetuning\n","- Special characters:\n","    - '`': Toxin start\n","    - '!': Antitoxin start\n","    - '@': Type II TA pair"]},{"cell_type":"markdown","metadata":{"id":"S1BBSJN-vg_6"},"source":["### Basic set up"]},{"cell_type":"markdown","metadata":{"id":"_tC-ZBaYvg_7"},"source":["Hyperparameters for Evo (8k)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"jgXtzUavvg_7"},"outputs":[],"source":["MAX_CONTEXT_LENGTH = 1024 # Context length for finetuning (including special tokens)\n","\n","TA_SPECIAL_TOKEN = {\n","    'T': '`', # Toxin gene\n","    'AT': '!', # Antitoxin gene\n","    '2' : '@' # Type II Toxin-Antitoxin\n","}"]},{"cell_type":"markdown","metadata":{"id":"ubX8PasNvg_9"},"source":["File directories and other information"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"diIzhpVQvg_9"},"outputs":[],"source":["# Define file paths\n","at_exp_file_path = '..\\\\raw_data\\\\type_II_AT_exp_nucl.fas'\n","at_pre_file_path = '..\\\\raw_data\\\\type_II_AT_pre_nucl.fas'\n","t_exp_file_path = '..\\\\raw_data\\\\type_II_T_exp_nucl.fas'\n","t_pre_file_path = '..\\\\raw_data\\\\type_II_T_pre_nucl.fas'\n","\n","csv_output = '..\\\\data\\\\processed_data.csv'\n","genome_csv_output = '..\\\\data\\\\NCBI_genome_data.csv'\n","json_output = '..\\\\data\\\\training_data_2.json'\n","\n","# NCBI Log in info\n","email_id = 'chang.m.yun@stanford.edu'"]},{"cell_type":"markdown","metadata":{"id":"q8ctZ0Hpvg_-"},"source":["Import modules"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xYMEAAc9vg_-"},"outputs":[],"source":["import argparse\n","from Bio import SeqIO, Entrez\n","import gzip\n","import json\n","import os\n","import pandas as pd\n","import re"]},{"cell_type":"markdown","metadata":{"id":"sqrbefCtvg__"},"source":["### Read FASTA files"]},{"cell_type":"markdown","metadata":{"id":"xKKJveipvg__"},"source":["Open, parse, and store as pandas dataFrames"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"H5GymcuVvhAA"},"outputs":[{"data":{"text/plain":["'\\nat_pre_df = fasta_to_df(at_pre_file_path)\\nt_pre_df = fasta_to_df(t_pre_file_path)\\n'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Functions\n","def parse_description(description=str):\n","    '''\n","    Parse description into 'Pair #', 'Accession', 'Start', 'End', 'Species'\n","    '''\n","\n","    # Define the regular expression pattern\n","    pattern = r'^(\\w+)\\s+(\\S+):c?(\\d+)-(\\d+)\\s+\\[(.*?)\\]$'\n","\n","    match = re.match(pattern, description)\n","    if match:\n","        # Extract information from matched groups\n","        code = match.group(1)\n","        accession = match.group(2)\n","        start = match.group(3)\n","        end = match.group(4)\n","        species = match.group(5)\n","\n","        # Return extracted information\n","        return code, accession, start, end, species\n","    else:\n","        # Return None if no match found\n","        return None\n","\n","def fasta_to_df(fasta_file_path=str, A_T=str, source=str, tat_type=str):\n","    '''\n","    Convert FASTA file into Pandas DataFrame\n","    '''\n","    # Define new pandas dataFrame: Source, Pair #, Accession #, Start position, End position, Sequence\n","    columns = ['type', 'source', 'pair_no', 'accession', 'start', 'end', 'seq']\n","    df = pd.DataFrame(columns=columns)\n","\n","    # Open FASTA file\n","    with open(fasta_file_path, \"r\") as fasta_handle:\n","        fasta_seqio = SeqIO.parse(fasta_handle, 'fasta')\n","\n","        # Populate FASTA into DataFrame\n","        for fasta in fasta_seqio:\n","            # Identify Header, Sequence, Description in FASTA\n","            header, seq, description = str(fasta.id), str(fasta.seq), str(fasta.description)\n","            if description:\n","                # Parse description\n","                code, accession, start, end, species = parse_description(description) # Ignore species name\n","                \n","                if A_T == 'AT':\n","                    pair_no = code[2:]\n","                else:\n","                    pair_no = code[1:]\n","\n","                # Append to DataFrame\n","                df = pd.concat([df, pd.DataFrame({'type': [str(tat_type)], 'source': [str(source)], 'pair_no': [pair_no], 'accession': [str(accession)], \\\n","                                                    'start': [int(start)],'end': [int(end)],'seq': [str(seq)]})], ignore_index=True)\n","    return df\n","\n","# Open each FASTA file and parse into pandas dataframe: at_exp_DF, T_exp_DF, AT_pre_DF, T_pre_DF\n","at_exp_df = fasta_to_df(at_exp_file_path, 'AT', 'exp', '2')\n","t_exp_df = fasta_to_df(t_exp_file_path, 'T', 'exp','2')\n","\n","'''\n","at_pre_df = fasta_to_df(at_pre_file_path)\n","t_pre_df = fasta_to_df(t_pre_file_path)\n","'''"]},{"cell_type":"markdown","metadata":{"id":"BtKDIqn7vhAA"},"source":["Pair Toxin-Antitoxin (TAT) pairs together"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"tRWpjbTdvhAB"},"outputs":[],"source":["# Combine toxin-antitoxin pairs, based on source, pair_no, accession\n","exp_paired_df = pd.merge(at_exp_df, t_exp_df, on=['type', 'source', 'pair_no', 'accession'], how='inner', suffixes=('_at','_t'))\n","'''\n","pre_paired_df = pd.merge(at_pre_DF, t_pre_DF, on=['type', 'source', 'pair_no', 'accession'], how='inner', suffixes=('_at','_t'))\n","\n","# Combine experimental + in silico predicted pairs\n","tat_paired_df = pd.concat([exp_paired_df, pre_paired_df], ignore_index=True)\n","'''\n","tat_paired_df = exp_paired_df # Temporary: Delete once uncommented"]},{"cell_type":"markdown","metadata":{},"source":["Identify operon strand in genome: Forward strand, Reverse strand"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Function\n","def strand_direction(row=pd.Series, A_T=str):\n","    if A_T == 'AT':\n","        # Identify antitoxin gene direction\n","        if row['start_at'] < row['end_at']:\n","            dir = 'F'\n","        elif row['start_at'] > row['end_at']:\n","            dir = 'R'\n","\n","    elif A_T == 'T':\n","        # Identify toxin gene direction\n","        if row['start_t'] < row['end_t']:\n","            dir = 'F'\n","        elif row['start_t'] > row['end_t']:\n","            dir = 'R'\n","    \n","    return dir\n","\n","# Identify strand direction: Forward vs. Reverse\n","tat_paired_df['dir_at'] = tat_paired_df.apply(strand_direction, axis=1, args=('AT',))\n","tat_paired_df['dir_t'] = tat_paired_df.apply(strand_direction, axis=1, args=('T',))"]},{"cell_type":"markdown","metadata":{"id":"xo-CQCw0vhAB"},"source":["Find operon position in genome"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[]\n"]}],"source":["# Check if Toxin-Antitoxin pair always in same operon\n","mask = tat_paired_df['dir_at'] != tat_paired_df['dir_t']\n","print(tat_paired_df.index[mask].tolist()) # If empty, Toxin-Antitoxin pair always in same operon\n","\n","# Take direction of Toxin gene as direction of operon\n","tat_paired_df['dir'] = tat_paired_df['dir_t']"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9ssj445evhAB"},"outputs":[{"data":{"text/plain":["\"\\n# Select max operon length (= context length for all operons)\\nmax_len_operon = tat_paired_df['len_operon'].max()\\nif max_len_operon < MAX_SEQ_LENGTH:\\n    max_len = max_len_operon\\nelse:\\n    max_len = MAX_SEQ_LENGTH\\n\""]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Find operon position: Start, End, Length (of Operon)\n","tat_paired_df['start_operon'] = tat_paired_df.apply(lambda row: min(row['start_at'], row['start_t'], row['end_at'], row['end_t']), axis=1)\n","tat_paired_df['end_operon'] = tat_paired_df.apply(lambda row: max(row['start_at'], row['start_t'], row['end_at'], row['end_t']), axis=1)\n","tat_paired_df['len_operon'] = tat_paired_df['end_operon'] - tat_paired_df['start_operon'] + 1\n","\n","'''\n","# Select max operon length (= context length for all operons)\n","max_len_operon = tat_paired_df['len_operon'].max()\n","if max_len_operon < MAX_SEQ_LENGTH:\n","    max_len = max_len_operon\n","else:\n","    max_len = MAX_SEQ_LENGTH\n","'''"]},{"cell_type":"markdown","metadata":{"id":"b7pqby0YvhAB"},"source":["### Find genomic regions"]},{"cell_type":"markdown","metadata":{"id":"kcqPBG7YvhAB"},"source":["Identify and fetch relevant genomes"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"nvFWC6A-vhAC"},"outputs":[],"source":["# Function\n","def NCBI_genome(accession=str):\n","    '''\n","    Access NCBI with email to return genome: Sequence\n","    '''\n","    Entrez.email = email_id\n","    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"fasta\", retmode=\"text\")\n","    record = SeqIO.read(handle, \"fasta\")\n","    handle.close()\n","    return str(record.seq)\n","\n","# Create new Pandas DataFrame with unique accession no.s\n","genome_df = pd.DataFrame(tat_paired_df['accession'].drop_duplicates())\n","\n","# Find NCBI genome sequence for each accession no.\n","genome_df['seq'] = genome_df['accession'].apply(NCBI_genome)"]},{"cell_type":"markdown","metadata":{},"source":["Export NCBI genome sequences as CSV file"]},{"cell_type":"code","execution_count":181,"metadata":{},"outputs":[],"source":["genome_df.to_csv(genome_csv_output)"]},{"cell_type":"markdown","metadata":{},"source":["Import NCBI genome sequences from CSV file"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["genome_df = pd.read_csv(genome_csv_output)"]},{"cell_type":"markdown","metadata":{"id":"JYIl2F5xvhAC"},"source":["Identify context length regions (+special token)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Assign full genome to each TAT pair\n","tat_paired_df = pd.merge(tat_paired_df, genome_df, on=['accession'], how='outer', suffixes=('_pair','_genome'))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"r1-3UcH_vhAC"},"outputs":[],"source":["# Function\n","def assemble_seq_context(row=pd.Series):\n","    # Tokens\n","    token_type = TA_SPECIAL_TOKEN[row['type']]\n","    token_t = TA_SPECIAL_TOKEN['T']\n","    token_at = TA_SPECIAL_TOKEN['AT']\n","\n","    # Case 1: Forward strand\n","    if row['dir'] == 'F':\n","        # Gene sequence\n","        gene_t = row['seq_genome'][row['start_t']:row['end_t']]\n","        gene_at = row['seq_genome'][row['start_at']:row['end_at']]\n","\n","        # Case 1-A: Toxin - Antitoxin\n","        # Type token + T token + Toxin gene + T token + Spacer + AT token + Antitoxin gene + AT token\n","        if row['start_t'] < row['start_at']:\n","            # Spacer sequence\n","            spacer = row['seq_genome'][row['end_t']+1:row['start_at']-1]\n","            \n","            seq_context = token_type + token_t + gene_t + token_t + spacer + token_at + gene_at + token_at\n","\n","        # Case 1-B: Antitoxin - Toxin\n","        # Type token + AT token + Antitoxin gene + Spacer + T token + Toxin gene\n","        elif row['start_t'] > row['start_at']:\n","            # Spacer sequence\n","            spacer = row['seq_genome'][row['end_at']+1:row['start_t']-1]\n","            \n","            seq_context = token_type + token_at + gene_at + token_at + spacer + token_t + gene_t + token_t\n","\n","    # Case 2: Reverse strand\n","    elif row['dir'] == 'R':\n","        # Gene sequence\n","        gene_t = row['seq_genome'][row['end_t']:row['start_t']]\n","        gene_at = row['seq_genome'][row['end_at']:row['start_at']]\n","\n","        # Case 2-A: Toxin - Antitoxin\n","        # AT token + Antitoxin gene + AT token + Spacer + T token + Toxin gene + T token + Type token\n","        if row['end_at'] < row['end_t']:\n","            # Spacer sequence\n","            spacer = row['seq_genome'][row['start_at']+1:row['end_t']-1]\n","\n","            seq_context = token_at + gene_at + token_at + spacer + token_t + gene_t + token_t + token_type\n","\n","        # Case 2-B: Antitoxin - Toxin\n","        # T token + Toxin gene + T token + Spacer + AT token + Antitoxin gene + AT token + Type token\n","        elif row['end_at'] > row['end_t']:\n","            # Spacer sequence\n","            spacer = row['seq_genome'][row['start_t']+1:row['end_at']-1]\n","        \n","            seq_context = token_t + gene_t + token_t + spacer + token_at + gene_at + token_at + token_type\n","\n","    # Add spaces if context length is shorter than max_len (eg when genome length is short)\n","    global MAX_CONTEXT_LENGTH\n","    if len(seq_context) < MAX_CONTEXT_LENGTH:\n","        num_spaces = MAX_CONTEXT_LENGTH - len(seq_context)\n","        padding_3 = ' ' * num_spaces\n","    else:\n","        padding_3 = ''\n","\n","    seq_context += padding_3\n","\n","    return seq_context\n","\n","# Add padding + operon + special token\n","tat_paired_df['seq_context'] = tat_paired_df.apply(assemble_seq_context, axis=1)                                             "]},{"cell_type":"markdown","metadata":{"id":"hkjCIaKVvhAD"},"source":["Export as CSV file"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"1_WE07CyvhAD"},"outputs":[],"source":["# tat_paired_df.to_csv(csv_output)"]},{"cell_type":"markdown","metadata":{"id":"xep_6VS0vhAD"},"source":["### Export as JSON file"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"3TGGpFgLvhAD"},"outputs":[],"source":["# Functions\n","def write_json(data, OUTPUT_PATH):\n","    with open(OUTPUT_PATH, 'at') as file:\n","        json.dump(data, file)\n","\n","def convert_df_to_list(df=pd.DataFrame):\n","    records = []\n","    global MAX_CONTEXT_LENGTH\n","\n","    for index, row in df.iterrows():\n","        # Append rows with context length less than or equal to max context length\n","        if len(row['seq_context']) <= MAX_CONTEXT_LENGTH:\n","            records.append({\n","                'record': row['pair_no'],\n","                'text': row['seq_context']\n","                })\n","\n","    return records\n","\n","# Convert Pandas DataFrame into list\n","data_list = convert_df_to_list(tat_paired_df)\n","\n","# Write JSON file from list\n","write_json(data_list, json_output)"]},{"cell_type":"markdown","metadata":{"id":"bCTXqPVyvhAE"},"source":["### Miscellaneous"]},{"cell_type":"code","execution_count":202,"metadata":{"id":"HiGQrD8-vhAE"},"outputs":[{"name":"stderr","output_type":"stream","text":["usage: ipykernel_launcher.py [-h] fasta_path metadata_path output_path\n","ipykernel_launcher.py: error: the following arguments are required: fasta_path, metadata_path, output_path\n"]},{"ename":"SystemExit","evalue":"2","output_type":"error","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\cmyun\\anaconda3\\envs\\jupyter\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}],"source":["'''\n","# From Evo CRISPR training\n","def parse_fasta_with_biopython(fname, id_to_cas_id):\n","    records = []\n","\n","    if fname.endswith('.gz'):\n","        file_ = gzip.open(fname, 'rt')\n","    else:\n","        file_ = open(fname, 'r')\n","\n","    for record in SeqIO.parse(file_, 'fasta'):\n","        seq = str(record.seq)\n","\n","        if 'NNN' in seq:\n","            continue\n","\n","        if len(seq) >= MAX_seq_LENGTH - 2: # Minus start and end tokens.\n","            extra = len(seq) - (MAX_seq_LENGTH - 2)\n","            seq = seq[:-extra]\n","\n","        cas_id = id_to_cas_id[record.id]\n","\n","        seq = CAS_ID_TO_START_TOKEN[cas_id] + seq # Encode start token.\n","        # Stop token (EOD) is appended in downstream preprocess_data.py script.\n","\n","        records.append({\n","            'record': record.id,\n","            'text': seq,\n","        })\n","\n","    file_.close()\n","\n","    return records\n","\n","\n","def write_json(fname, data, output_path):\n","    with open(output_path, 'at') as f:\n","        for record in data:\n","            f.write(json.dumps(record) + '\\n')\n","\n","\n","def process_file(fname, id_to_cas_id, output_file):\n","    parsed_data = parse_fasta_with_biopython(fname, id_to_cas_id)\n","    write_json(fname, parsed_data, output_file)\n","\n","\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser(description=\"Parse Cas sequences and output JSONL.\")\n","    parser.add_argument(\"fasta_path\", type=str,\n","                        help=\"Path to directory containing input FASTA file.\")\n","    parser.add_argument(\"metadata_path\", type=str,\n","                        help=\"Path to Cas metadata file.\")\n","    parser.add_argument(\"output_path\", type=str,\n","                        help=\"Path to output JSON file.\")\n","    args = parser.parse_args()\n","\n","    id_to_cas_id = load_metadata(args.metadata_path)\n","\n","    process_file(args.fasta_path, id_to_cas_id, args.output_path)\n","'''"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"jupyter","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
